{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f143a0a-7df9-4579-b8ef-f5ea5be3adda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89589725-f253-40d3-9f1d-7afea84a9887",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:46:45.895790900Z",
     "start_time": "2024-06-05T08:46:43.970591400Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d9dec8-05eb-418d-bb5f-d1f1998acf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"05-cifar10-cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e04ab-1cc7-4669-a176-487c0cd487a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
    "download_url(dataset_url, \".\")  # downloaded directly by visiting the url. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e02f33-aea4-45a7-a85e-bbb24d1dad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(\"./cifar10.tgz\", \"r:gz\") as tar:\n",
    "    tar.extractall(path=\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcae29a-934b-43b0-bcc4-829d1493c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/cifar10\"\n",
    "\n",
    "print(os.listdir(data_dir))\n",
    "classes = os.listdir(data_dir + \"/train\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec3afe8-22e7-4517-a9cd-40c11a78677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "airplane_files = os.listdir(data_dir + \"/train/airplane\")\n",
    "print(\"No. of training examples for airplanes:\", len(airplane_files))\n",
    "print(airplane_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249a398-f599-41d4-8d9f-80ce3fb68cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_test_files = os.listdir(data_dir + \"/test/ship\")\n",
    "print(\"No. of test examples for ship:\", len(ship_test_files))\n",
    "print(ship_test_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a73c6-1010-4e1a-8ab5-fba3b3638864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder  # A generic data loader where the images are arranged in a specific way.\n",
    "from torchvision.transforms import ToTensor  # ToTensor is a class with a magic method `__call__()`, so it can be regarded as function. It is used to transform an input image and return a transformed version of the image, like a Tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "379646b7-6556-4095-a729-f9f9c3524a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data/cifar10/train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ImageFolder(data_dir+\"/train\", transform=ToTensor())  # it has __iter__ magin method.\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402adb1a-e571-4191-bb17-edf3c3a7ec2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c6a5e1-2119-4c28-be2d-bbdf311d6527",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = dataset[0]  # __getitem__() magic method is owned/set in DatasetFolder class. The return value of indexing or dataset is a tuple, from self.samples, generated by self.make_dataset < make_dataset->a list with its component of a form (path_to_sample, class_index).\n",
    "print(type(dataset[0]))  # this is a tuple. Why the return value of indexing dataset is a tuple object is because the return value of the magic method __getitem__ is two values, one is sample and target.\n",
    "# Node: the first value is sample, one element of samples, not samples.\n",
    "print(img.shape, label)\n",
    "img  # this is a torch.Tensor\n",
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3300704b-9d2a-45d0-89b2-d4fe71b3736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset.imgs)  # dataaset is a dict object, and dataset.imgs is a list object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef4edd-0cf1-4d24-b1d2-de15d02da0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(dataset, dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e5496-0b3c-42c0-b2f9-3b388d3ec172",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)  # torchvision.datasets.folder.ImageFolder, it's a folder object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af0fc9c-88a8-4b3a-b735-de71d7c7e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.imgs[0]  # the imgs attribute is set by self.samples, i.e., self.imgs = self.samples, which is a list with its element as a form of (path_to_sample, class_index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab38d5-0946-459d-bf67-43a51638dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]  # it equals to (dataset.transform(dataset.loader(dataset.imgs[0])), dataset.imgs[1])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed092c1-8b7a-4ebd-8648-061628ed53f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sample = dataset.imgs[0]\n",
    "first_sample\n",
    "dataset.loader(first_sample[0])  # loader is used to load an image given its path. In this case, the loader is an instance of DatasetFolder, inherited from VisionDataset.\n",
    "# transform is used to convert the image to a pytorch.Tensor, a matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8707ea7-9c16-4876-a1ed-7a1f1d0d7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(first_sample)  # the type of the data element is tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c3800a-cb4e-47ff-af14-160be94a9725",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sample  # it is composed of tensor and its label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7d10a5-ad2e-46f7-8ce8-259fd8a0e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(first_sample)  # the type of the data element is tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbb2273-e03c-40de-9a15-41fcc3a75db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.transform(dataset.loader(first_sample[0]))  # loader is an object of DatasetFolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9ba18-c823-4b9d-9168-29f1a1e579f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = first_sample  # (path_to_sample, class_index)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77302575-b79c-4bc8-81e2-3d6d1591ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdaf473-47e4-47c4-b534-57ec78f44d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img)  # the type of the dataset element is a tuple with its first element of torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b66f9-15ba-46c1-99ea-5bd7b8eed6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dataset.transform(dataset.loader(img))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9816cf0-a4f7-49da-87ce-20356599d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.classes)\n",
    "print(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59348fc-ac9e-4aaf-bc04-aee99ea52c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# the inline keyword here is used to tell the tool that show the picture in the window, other than to a new window.\n",
    "\n",
    "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59deb63-1d35-4a4f-be6e-51919a205d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(img, label):  # here lable is an int object.\n",
    "    print(\"Label: \", dataset.classes[label], \"(\" + str(label) + \")\")\n",
    "    plt.imshow(img.permute(1, 2, 0))  # TODO find out how permute works in pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ba65d-7989-4378-b86d-a5e5cfbe21f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(*dataset[0])  # star operator here is used to tear the tuple apart and set the values to nominal arguments, i.e. img and label\n",
    "show_example(*dataset[3])  # star operator here is used to tear the tuple apart and set the values to nominal arguments, i.e. img and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c73be-b8bc-4109-bd76-92295ce42a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sample[0].permute(1, 2, 0)  # this function is used to change the dimensions of the tensor # TODO I dont understand this method a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80005ae8-67a9-40d8-ae85-317f5670adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sample[0]  # 32 rows, 32 cols, and 3 channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648bd32-1a91-4b51-8c9b-a85a54e54c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdadf254-df95-481b-af3f-e7e48fd00404",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)  # to set the seed for generating random numbers. Returns a torch.Generator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a1827-22d4-41c7-9551-03639f53767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 5000  # this is the validation test set length.\n",
    "train_size = len(dataset) - val_size  # this is the train set size. Why dataset has the len attribute is because its orginated class has the __len__ magic method.\n",
    "\n",
    "# randomly split a dataset into non-overlapping new datasets of given lengths, the lengths is also an input argument of this method, with its as Sequence instance.\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])  # random_split method is imported from torch.utils.data\n",
    "# the return value of random_split is a list of subsets.\n",
    "\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8a7c6-5575-4248-8c5f-1807e33c9e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406ce76-91f7-48e4-b804-80f8fff8a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set shuffle to true to have the data reshuffled at every epoch.\n",
    "# set pin_memory to true, the data loader will copy Tensors into device/CUDA pinned memory before returning them.\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38fb37e-7433-4034-81b1-058e472bfdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid  # it is a function to make a grid of images.\n",
    "\n",
    "def show_batch(dl):  # here dl is a dataset.\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
    "        break\n",
    "\n",
    "show_batch(train_dl)\n",
    "# print(\"*\" * 10)\n",
    "# show_batch(train_dl)\n",
    "\n",
    "def apply_kernel(image, kernel):  # image is a Tensor. And also kernel.\n",
    "    # pay attention to the size calculation\n",
    "    ri, ci = image.shape\n",
    "    rk, ck = kernel.shape\n",
    "    ro, co = ri - rk + 1, ci - ck + 1\n",
    "    output = torch.zeros([ro, co])\n",
    "    for i in range(ro):\n",
    "        for j in range(co):\n",
    "            output[i, j] = torch.sum(image[i:i+rk, j:j+ck] * kernel)  # TODO image[i:i+rk, j:j+ck] * kernel, this is elementwise multiplication.\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8dd294-09d7-4b97-93df-f3eff81be54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of elementwise multiplication.\n",
    "sample_image = torch.tensor([\n",
    "    [3, 3, 2, 1, 0],\n",
    "    [0, 0, 1, 3, 1],\n",
    "    [3, 1, 2, 2, 3],\n",
    "    [2, 0, 0, 2, 2],\n",
    "    [2, 0, 0, 0, 1]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "sample_kernel = torch.tensor([\n",
    "    [0, 1, 2], \n",
    "    [2, 2, 0], \n",
    "    [0, 1, 2]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "apply_kernel(sample_image, sample_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1885e171-0595-40d2-8401-b4bfb832bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b595b5d-2ea6-441f-b036-b154ad1726c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = nn.Sequential(\n",
    "    nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1),  # the nominal arguments of this model `nn.Conv2d` are in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype.\n",
    "    nn.MaxPool2d(2, 2)\n",
    ")  # Sequential has method called `forward`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c59d19-0232-4961-8bd6-c048544af22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_dl:\n",
    "    print('images.shape:', images.shape)\n",
    "    out = simple_model(images)  # the return value of this model is also a Tensor.\n",
    "    print('out.shape:', out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7804c810-ebc6-487a-806c-40cc1320a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):  \n",
    "    # in this class, the tutor defined these four methods in order to use them directly along the way to generate the model.\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        print(\">>>>> >>> inside the training_step method: \", type(self), id(self))\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = accuracy(out, labels)\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)  # torch.max returns the tensor with the maximum value in the given dimension\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f76a4-db9d-47ec-a514-e8855ea6eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10CnnModel(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10))  # Sequential object has the common/similar methods like add, insert, pop, , extend, etc. as List does.\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24783381-1b8d-48fe-8140-07d3f519c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cifar10CnnModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093112a-b6ef-4f71-aaf2-7e2eed10f0c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for images, labels in train_dl:  # each item getting from train_dl's iterator is a batch item, with batch_size(128) samples in it\n",
    "    print('images.shape:', images.shape)\n",
    "    out = model(images)\n",
    "    print('out.shape:', out.shape)\n",
    "    print('out[0]:', out[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93f5f10-7f8e-4415-9559-37947b459469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da05c02-dbee-4456-8af3-d14144cd0280",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_dl:\n",
    "    print(type(item))\n",
    "    # print(item)\n",
    "    print(len(item[0]), len(item[1]))\n",
    "    print(type(item[0]))\n",
    "    print(item[0])\n",
    "    print(item[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d607eea-0050-42e8-a0c3-d8ea2fc40ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):  # if the data is a list of tuple instance, then the return value of this function is a list either, with data.to(device, non_blocking=True) as its component.\n",
    "    if isinstance(data, (list, tuple)):  # to check if data is one of the type of list and tuple\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec09817-d83d-486c-a2f3-55090a38e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d712ec1-d2a2-48c2-a5b4-e510e47e07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)  # Here, it just creates a DeviceDataLoader instance for training data, but hasnt loaded data to the device yet.\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f81b62-1a52-4e08-bc89-a68ec35f63db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d57e188-4b20-461b-8c90-1ce75f5dc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()  # TODO find out what this decorator is for.\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()  # this method is to set the module in evaluation mode. The return of this method is a trained model.\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]  # in this case, the batch size is 128.\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):  # optimization_function\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)  # this is how to optmize the parameters in the model.\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # set the model in training mode.\n",
    "        train_losses = []\n",
    "        for batch in train_loader:  # train_loader is a DataLoader object.\n",
    "            loss = model.training_step(batch)  # TODO find out how the model treat the bacth data. Answer: this whole model trains the data in batches, each batch will have a loss.\n",
    "            print(\"inside fit function:\", type(model), id(model))\n",
    "            train_losses.append(loss)  # batch loss\n",
    "            loss.backward()\n",
    "            optimizer.step()  # perform a single optimization step (parameter update).\n",
    "            optimizer.zero_grad()  # these operations are accumulated on the same model, which means the model stores the parameters inside.\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd985db-76f2-4a7b-99d2-dc62d93320a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_device(Cifar10CnnModel(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17148c1a-9ada-4e51-9b58-e169ff5bdf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10bde72-0d7b-4ab5-b572-202ecb6b4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3c9610-bc58-4075-aa6f-700522065f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ecb1c4-cb39-4d31-ad20-95e766632496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1217ff3-e26e-4086-85e7-61baefbb1cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab401b2-5c60-4764-8096-195769d73dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', \"Validation\"])\n",
    "    plt.title('Loss vs. No. of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efb9da2-ce2b-4ffd-864b-1439c32eedc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202bebe1-03cf-4a10-b9c8-293e19ca3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ImageFolder(data_dir + '/test', transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1054f814-fb28-47bb-bac3-31524aa49844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    yb = model(xb)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    return dataset.classes[preds[0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c0da92-dfe4-47b3-8c48-b7a14e3b3638",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dfc663-5154-456e-899d-aa46d7301169",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_dataset[1002]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48136db3-181c-4a87-bd7d-fff568464daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_dataset[6153]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48106e45-85ae-45de-af05-1412d246164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size*2), device)\n",
    "result = evaluate(model, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d5695e-0e20-4a4f-ac11-69ddc67ce43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'cifar10-cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8269075-dcc3-414c-a4ea-b0e96118101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf69f88-79ef-4526-abc3-ee0c7458f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1538deb-c570-4aa8-971e-e16b2a338e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in model.state_dict().items():\n",
    "    print(v)\n",
    "    print(\"<\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e2df19-b267-47ba-8d1a-644d1b930e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = to_device(Cifar10CnnModel(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f05523-15a6-4d99-9859-70e84fae07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_state_dict(torch.load('cifar10-cnn.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab2021b-b229-4074-a8c4-5cd3d7f7a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model2, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c99ad9-776b-4c8c-b984-071272ab3738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
